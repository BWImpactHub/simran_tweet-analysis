{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import nltk\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import regex as re\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "\n",
    "# Scipy\n",
    "import scipy\n",
    "\n",
    "\n",
    "# Train-test split and cross validation\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB        \n",
    "# from sklearn.naive_bayes import MultinomialNB     \n",
    "from sklearn.naive_bayes import BernoulliNB     \n",
    "from sklearn.naive_bayes import CategoricalNB  \n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Data Gathering ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dfsample=pd.read_csv('/content/drive/MyDrive/BW_projects/sample_submission.csv')\n",
    "dfsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dftrain=pd.read_csv('/content/drive/MyDrive/BW_projects/train.csv')\n",
    "dftrain.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dftest=pd.read_csv('/content/drive/MyDrive/BW_projects/test.csv')\n",
    "dftest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dftrain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dftrain.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dftrain.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#checking for missing values\n",
    "null_counts = dftrain.isnull().sum()\n",
    "null_percentage = (null_counts / len(dftrain)) * 100\n",
    "sns.barplot(x=null_percentage.index, y=null_percentage)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dftrain['keyword'] = dftrain['keyword'].fillna('unknown')\n",
    "dftrain['location'] = dftrain['location'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(dftrain[['keyword', 'location']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4))\n",
    "null_counts = dftrain.isnull().sum()\n",
    "null_percentage = (null_counts / len(dftrain)) * 100\n",
    "sns.barplot(x=null_percentage.index, y=null_percentage)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#checking for duplicate values\n",
    "dftrain.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dftrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dftest.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dftrain['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(dftrain['target'].value_counts(), labels=['disaster','not_disaster'],autopct=\"%0.2f\",colors='yc',explode=[0.3,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking strenght of characters in each class\n",
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
    "tweet_len= dftrain[dftrain['target']==1]['text'].str.len()\n",
    "ax1.hist(tweet_len,color='red')\n",
    "ax1.set_title('disaster tweets')\n",
    "tweet_len=dftrain[dftrain['target']==0]['text'].str.len()\n",
    "ax2.hist(tweet_len,color='green')\n",
    "ax2.set_title('Not disaster tweets')\n",
    "fig.suptitle('Characters in tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num of words\n",
    "dftrain['words_count']=dftrain['text'].apply(lambda x:len(nltk.word_tokenize(x)))\n",
    "\n",
    "total_words = dftrain['words_count'].sum()\n",
    "dftrain['words_percentage'] = (dftrain['words_count'] / total_words) * 100\n",
    "\n",
    "#Spliting into disaster and non-disaster tweets\n",
    "dftraindisa = dftrain[dftrain['target'] == 1]['words_percentage']\n",
    "dftrainnondisa = dftrain[dftrain['target'] == 0]['words_percentage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
    "ax1.violinplot(dftraindisa,showmeans=True)\n",
    "ax1.set_title('disaster tweets')\n",
    "ax2.violinplot(dftrainnondisa,showmeans=True)\n",
    "ax2.set_title('Not disaster tweets')\n",
    "fig.suptitle('words in tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "# stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to lowercase\n",
    "def convert_to_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "text = \"This is a FUNCTION that CoNvErTs a Text to lowercase\"\n",
    "print(\"Input: {}\".format(text))\n",
    "print(\"Output: {}\".format(convert_to_lowercase(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing whitespaces\n",
    "def remove_whitespace(text):\n",
    "    return text.strip()\n",
    "\n",
    "text = \" \\t This is a string \\t \"\n",
    "print(\"Input: {}\".format(text))\n",
    "print(\"Output: {}\".format(remove_whitespace(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuations\n",
    "def remove_punctuation(text):\n",
    "    punct_str = string.punctuation\n",
    "    punct_str = punct_str.replace(\"'\", \"\") # discarding apostrophe from the string to keep the contractions intact\n",
    "    return text.translate(str.maketrans(\"\", \"\", punct_str))\n",
    "\n",
    "text = \"Here's [an] example? {of} &a string. with.? punctuations!!!!\"\n",
    "print(\"Input: {}\".format(text))\n",
    "print(\"Output: {}\".format(remove_punctuation(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing HTML tags\n",
    "def remove_html(text):\n",
    "    html = re.compile(r'<.*?>')\n",
    "    return html.sub(r'', text)\n",
    "\n",
    "text = '<a href = \"https://www.online.com\"> tweet Classification </a>'\n",
    "print(\"Input: {}\".format(text))\n",
    "print(\"Output: {}\".format(remove_html(text)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing other unicode characters\n",
    "def remove_http(text):\n",
    "    http = \"https?://\\S+|www\\.\\S+\" # matching strings beginning with http (but not just \"http\")\n",
    "    pattern = r\"({})\".format(http) # creating pattern\n",
    "    return re.sub(pattern, \"\", text)\n",
    "\n",
    "text = \"It's a function that removes links starting with http: or https such as https://en.wikipedia.org/wiki/Unicode_symbols\"\n",
    "print(\"Input: {}\".format(text))\n",
    "print(\"Output: {}\".format(remove_http(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords\n",
    "stops = stopwords.words(\"english\") # stopwords\n",
    "addstops = [\"among\", \"onto\", \"shall\", \"thrice\", \"thus\", \"twice\", \"unto\", \"us\", \"would\"] # additional stopwords\n",
    "allstops = stops + addstops\n",
    "\n",
    "print(allstops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove stopwords from a list of texts\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in regexp.tokenize(text) if word not in allstops])\n",
    "\n",
    "text = \"This is a function that removes stopwords in a given text\"\n",
    "print(\"Input: {}\".format(text))\n",
    "print(\"Output: {}\".format(remove_stopwords(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "spacy_lemmatizer = spacy.load(\"en_core_web_sm\", disable = ['parser', 'ner'])\n",
    "#lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def text_lemmatizer(text):\n",
    "    text_spacy = \" \".join([token.lemma_ for token in spacy_lemmatizer(text)])\n",
    "    #text_wordnet = \" \".join([lemmatizer.lemmatize(word) for word in word_tokenize(text)]) # regexp.tokenize(text)\n",
    "    return text_spacy\n",
    "    #return text_wordnet\n",
    "\n",
    "text = \"Introducing lemmatization as an improvement over stemming\"\n",
    "print(\"Input: {}\".format(text))\n",
    "print(\"Output: {}\".format(text_lemmatizer(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp = RegexpTokenizer(r'\\w+') # Initialize the RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain['transformed_text'] = (dftrain[\"text\"].apply(convert_to_lowercase)\n",
    "                                     .apply(remove_punctuation) \n",
    "                                     .apply(remove_whitespace)\n",
    "                                     .apply(remove_html)\n",
    "                                     .apply(remove_http)\n",
    "                                     .apply(remove_stopwords)\n",
    "                                     .apply(text_lemmatizer)\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain['tokens'] = (dftrain[\"text\"].apply(convert_to_lowercase)\n",
    "                                    .apply(remove_punctuation) \n",
    "                                    .apply(remove_whitespace)\n",
    "                                    .apply(remove_html)\n",
    "                                    .apply(remove_http)\n",
    "                                    .apply(remove_stopwords)\n",
    "                                    .apply(regexp.tokenize))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec / Vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "wc = WordCloud(width=500,height=500,min_font_size=10,background_color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disaster_wc = wc.generate(dftrain[dftrain['target'] == 1]['transformed_text'].str.cat(sep=\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.imshow(Disaster_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nondisaster_wc = wc.generate(dftrain[dftrain['target'] == 0]['transformed_text'].str.cat(sep=\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.imshow(Nondisaster_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disaster_corpus = []\n",
    "for msg in dftrain[dftrain['target'] == 1]['tokens']:\n",
    "    for word in msg:\n",
    "        Disaster_corpus.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Disaster_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "comDisa=pd.DataFrame(Counter(Disaster_corpus).most_common(30))[0]\n",
    "comDisa\n",
    "comDisa_count=pd.DataFrame(Counter(Disaster_corpus).most_common(30))[1]\n",
    "comDisa_count\n",
    "sns.barplot(x=comDisa,y=comDisa_count)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NonDisaster_corpus = []\n",
    "for msg in dftrain[dftrain['target'] == 0]['tokens']:\n",
    "    for word in msg:\n",
    "        NonDisaster_corpus.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(NonDisaster_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comnon=pd.DataFrame(Counter(NonDisaster_corpus).most_common(30))[0]\n",
    "comnon\n",
    "comnon_count=pd.DataFrame(Counter(NonDisaster_corpus).most_common(30))[1]\n",
    "comnon_count\n",
    "sns.barplot(x=comnon,y=comnon_count)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain=dftrain[['tokens','target']]\n",
    "dftrain.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Vectorization\n",
    "# using word2vec\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(\n",
    "    sentences=dftrain['tokens'],  # Tokenized sentences\n",
    "    vector_size=200,         # Size of the embedding vectors\n",
    "    window=5,                # Context window size\n",
    "    min_count=1,             # Minimum frequency of words\n",
    "    workers=4,               # Number of CPU cores to use\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Train Word2Vec model\n",
    "# model = Word2Vec(sentences, vector_size=200, window=5, min_count=1,sg=0, workers=4)\n",
    "\n",
    "# 3. Generate sentence vectors (document embeddings)\n",
    "def get_sentence_vector(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "dftrain['sentence_vector'] = dftrain['tokens'].apply(lambda x: get_sentence_vector(x, w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Prepare data for classification\n",
    "X = np.stack(dftrain['sentence_vector'].values)\n",
    "y = dftrain['target'].values  # Assuming 'target' is your target variable column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Train a classifier (e.g., Logistic Regression)\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Make predictions on the test set\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "print(f\"Classification Report:\\n{class_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)  # Create classifier\n",
    "rf_classifier.fit(X_train, y_train)                                       # Train the classifier\n",
    "y_pred_rf = rf_classifier.predict(X_test)                                   # Make predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Evaluate Random Forest\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIVE BAYES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Naive Bayes Classifier (GaussianNB)\n",
    "nb_classifier = GaussianNB()              # Create classifier\n",
    "nb_classifier.fit(X_train, y_train)        # Train the classifier\n",
    "y_pred_nb = nb_classifier.predict(X_test)  # Make predictions\n",
    "\n",
    "#  Evaluate Naive Bayes\n",
    "print(\"\\nNaive Bayes Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_nb))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Bernoulli Naive Bayes\n",
    "bnb_classifier = BernoulliNB()      # Create classifier\n",
    "bnb_classifier.fit(X_train, y_train) # Train the classifier\n",
    "y_pred_bnb = bnb_classifier.predict(X_test)  # Make predictions\n",
    "\n",
    "# Evaluate Bernoulli Naive Bayes\n",
    "print(\"\\nBernoulli Naive Bayes:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_bnb))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_bnb))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
