{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import nltk\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import regex as re\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "\n",
    "# Scipy\n",
    "import scipy\n",
    "\n",
    "\n",
    "# Train-test split and cross validation\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB        \n",
    "# from sklearn.naive_bayes import MultinomialNB     \n",
    "from sklearn.naive_bayes import BernoulliNB     \n",
    "from sklearn.naive_bayes import CategoricalNB  \n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## **Problem statement**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dfsample=pd.read_csv('/content/drive/MyDrive/BW_projects/sample_submission.csv')\n",
    "dfsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dftrain=pd.read_csv('/content/drive/MyDrive/BW_projects/train.csv')\n",
    "dftrain.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dftest=pd.read_csv('/content/drive/MyDrive/BW_projects/test.csv')\n",
    "dftest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dftrain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dftrain.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dftrain.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#checking for missing values\n",
    "null_counts = dftrain.isnull().sum()\n",
    "null_percentage = (null_counts / len(dftrain)) * 100\n",
    "sns.barplot(x=null_percentage.index, y=null_percentage)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dftrain['keyword'] = dftrain['keyword'].fillna('unknown')\n",
    "dftrain['location'] = dftrain['location'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(dftrain[['keyword', 'location']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4))\n",
    "null_counts = dftrain.isnull().sum()\n",
    "null_percentage = (null_counts / len(dftrain)) * 100\n",
    "sns.barplot(x=null_percentage.index, y=null_percentage)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#checking for duplicate values\n",
    "dftrain.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dftrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dftest.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dftrain['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(dftrain['target'].value_counts(), labels=['disaster','not_disaster'],autopct=\"%0.2f\",colors='yc',explode=[0.3,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking strenght of characters in each class\n",
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
    "tweet_len= dftrain[dftrain['target']==1]['text'].str.len()\n",
    "ax1.hist(tweet_len,color='red')\n",
    "ax1.set_title('disaster tweets')\n",
    "tweet_len=dftrain[dftrain['target']==0]['text'].str.len()\n",
    "ax2.hist(tweet_len,color='green')\n",
    "ax2.set_title('Not disaster tweets')\n",
    "fig.suptitle('Characters in tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num of words\n",
    "dftrain['words_count']=dftrain['text'].apply(lambda x:len(nltk.word_tokenize(x)))\n",
    "\n",
    "total_words = dftrain['words_count'].sum()\n",
    "dftrain['words_percentage'] = (dftrain['words_count'] / total_words) * 100\n",
    "\n",
    "#Spliting into disaster and non-disaster tweets\n",
    "dftraindisa = dftrain[dftrain['target'] == 1]['words_percentage']\n",
    "dftrainnondisa = dftrain[dftrain['target'] == 0]['words_percentage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
    "ax1.violinplot(dftraindisa,showmeans=True)\n",
    "ax1.set_title('disaster tweets')\n",
    "ax2.violinplot(dftrainnondisa,showmeans=True)\n",
    "ax2.set_title('Not disaster tweets')\n",
    "fig.suptitle('words in tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
